{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVmwN903oRDi"
      },
      "source": [
        "# A Novel Cascade Binary Tagging Framework for Relational Triple Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35tSZaA3rwUC",
        "outputId": "fffce0fc-7688-43e1-984b-eebc01756356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "os.chdir('/content/gdrive/MyDrive/CasRel')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615,
          "referenced_widgets": [
            "85c629e1261c45258099cac20ae93a80",
            "eeaede3c17854fc884ec86fb6671f9a9",
            "ecbd5e139a324336a2f66fa81daff8a0",
            "0b17cc9fbe134ab8bfda63f16c857354",
            "b2e7ed35c4f74bd69673467fad7dacac",
            "ee1008c9342742ca93f596ac02354cca",
            "04a020d344764dbaa9b65bc2f8663c1f",
            "a6fc2a90096048b8b22a49da90f37411",
            "0331243d251e4cc092365e0342eb9a75",
            "7243c52e40c1485885fb16409e56e8a7",
            "7c0e8c317bf7478d8792e208062173e3",
            "3cbfa643d0f94b8e9e600ef2f9790c5c",
            "1683dc0fdaf64063ac17ace7964a218d",
            "14ac2ddf2fff4200b71770b3ce315a1d",
            "188cc792d6584f9a8fb41fffc6232d07",
            "b0d2b0a2a39944868e005f025c29325c",
            "c6b25463dc2c4e91beabca3292856f05",
            "b24c02447fa24936b3eef12cc6519f4d",
            "248510a1141347dc8c6a985c4a0fd7c8",
            "12dffa4cd7b642c0afbf4a9a913cdea2",
            "4c76ca8cd1c34258bbbb7be473b8fd4a",
            "db11a8a4bc1b43a8a06557d34350ba84",
            "91b1ac3f20164d6995c2a54f406818b3",
            "7023bd59b09b49069d6464781a22567e",
            "fb641842ab5d43169ae597d7e51f41e6",
            "81af793eb449404487cd22d5db65de09",
            "b9731845b1e84dc7a1101634515d834b",
            "c572966776bf4361a3761674b2679fcf",
            "0c3928456a8043658497699e1f65e91c",
            "348261ac505e41bfae5b44fc49839418",
            "497a6437c9784d3592ff15bb8ecb05a7",
            "d80d413c845f4ba1b7186c4878abba65",
            "6573b2b470304d158d7e0ba1e3ffc1b7"
          ]
        },
        "id": "WuBiGs36pa-P",
        "outputId": "76fb8ffe-f422-4d9f-a683-e67f2bfb5bd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 4.7 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 72.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 86.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.2 transformers-4.24.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85c629e1261c45258099cac20ae93a80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3cbfa643d0f94b8e9e600ef2f9790c5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91b1ac3f20164d6995c2a54f406818b3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
        "import config\n",
        "import time\n",
        "import argparse\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from random import choice\n",
        "import pickle\n",
        "import json\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "! pip install transformers\n",
        "import transformers\n",
        "from transformers import BertModel,BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLf71L11oRDo"
      },
      "source": [
        "### 4.1 Hyperparameter Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VYYgAaQooRDo",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "seed = 1234\n",
        "BERT_MAX_LEN = 512\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--model_name', type=str, default='Casrel', help='name of the model')\n",
        "parser.add_argument('--lr', type=float, default=1e-5)\n",
        "parser.add_argument('--multi_gpu', type=bool, default=False)\n",
        "parser.add_argument('--dataset', type=str, default='NYT')\n",
        "parser.add_argument('--batch_size', type=int, default=6)  \n",
        "parser.add_argument('--max_epoch', type=int, default=300)\n",
        "parser.add_argument('--test_epoch', type=int, default=1)\n",
        "parser.add_argument('--train_prefix', type=str, default='train_triples')\n",
        "parser.add_argument('--dev_prefix', type=str, default='dev_triples')\n",
        "parser.add_argument('--test_prefix', type=str, default='test_triples')\n",
        "parser.add_argument('--max_len', type=int, default=100)\n",
        "parser.add_argument('--rel_num', type=int, default=25)\n",
        "parser.add_argument('--period', type=int, default=1000)\n",
        "parser.add_argument('--debug', type=bool, default=False)\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "con = config.Config(args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "con.__dict__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVjJI1HcYOu3",
        "outputId": "70b36b86-37f1-477e-9b7c-8240ef02c6ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'args': Namespace(batch_size=6, dataset='NYT', debug=False, dev_prefix='dev_triples', lr=1e-05, max_epoch=300, max_len=100, model_name='Casrel', multi_gpu=False, period=1000, rel_num=25, test_epoch=1, test_prefix='test_triples', train_prefix='train_triples'),\n",
              " 'multi_gpu': False,\n",
              " 'learning_rate': 1e-05,\n",
              " 'batch_size': 6,\n",
              " 'max_epoch': 300,\n",
              " 'max_len': 100,\n",
              " 'rel_num': 25,\n",
              " 'dataset': 'NYT',\n",
              " 'root': '/content/gdrive/MyDrive/CasRel',\n",
              " 'data_path': '/content/gdrive/MyDrive/CasRel/data/NYT',\n",
              " 'checkpoint_dir': '/content/gdrive/MyDrive/CasRel/checkpoint/NYT',\n",
              " 'log_dir': '/content/gdrive/MyDrive/CasRel/log/NYT',\n",
              " 'result_dir': '/content/gdrive/MyDrive/CasRel/result/NYT',\n",
              " 'train_prefix': 'train_triples',\n",
              " 'dev_prefix': 'dev_triples',\n",
              " 'test_prefix': 'test_triples',\n",
              " 'model_save_name': 'Casrel_DATASET_NYT_LR_1e-05_BS_6',\n",
              " 'log_save_name': 'LOG_Casrel_DATASET_NYT_LR_1e-05_BS_6',\n",
              " 'result_save_name': 'RESULT_Casrel_DATASET_NYT_LR_1e-05_BS_6.json',\n",
              " 'period': 1000,\n",
              " 'test_epoch': 1,\n",
              " 'debug': False}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNRQ9w4moRDx"
      },
      "source": [
        "# Sequence Framework Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Y-UlBH5HYuvV"
      },
      "outputs": [],
      "source": [
        "def find_head_idx(source, target):\n",
        "    target_len = len(target)\n",
        "    for i in range(len(source)):\n",
        "        if source[i: i + target_len] == target:\n",
        "            return i\n",
        "    return -1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2rel = {}\n",
        "rel2id = json.load(open(os.path.join(con.data_path, 'rel2id.json')))\n",
        "for t in rel2id.keys():\n",
        "  id2rel[str(rel2id[t])] = t\n",
        "id2rel\n",
        "\n",
        "js_object = json.dumps(id2rel, indent=4)\n",
        "with open('id2rel.json','w') as f:\n",
        "  f.write(js_object)"
      ],
      "metadata": {
        "id": "mFGJIECdbtYM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dPaYytvWoRDx"
      },
      "outputs": [],
      "source": [
        "class CMEDDataset(Dataset):\n",
        "    def __init__(self, config, prefix, is_test, tokenizer):\n",
        "        self.config = config\n",
        "        self.prefix = prefix\n",
        "        self.is_test = is_test\n",
        "        self.tokenizer = tokenizer\n",
        "        if self.config.debug:\n",
        "            self.json_data = pickle.load(open(os.path.join(self.config.data_path, prefix + '.pkl'), 'rb'))[:500]\n",
        "        else:\n",
        "            self.json_data = pickle.load(open(os.path.join(self.config.data_path, prefix + '.pkl'), 'rb'))\n",
        "        self.rel2id = json.load(open(os.path.join(con.data_path, 'rel2id.json')))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.json_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ins_json_data = self.json_data[idx]\n",
        "        text = ins_json_data['text']\n",
        "        text = ' '.join(text.split()[:self.config.max_len])\n",
        "        tokens = self.tokenizer.tokenize(text)\n",
        "        if len(tokens) > BERT_MAX_LEN:\n",
        "            tokens = tokens[: BERT_MAX_LEN]\n",
        "        text_len = len(tokens)\n",
        "\n",
        "        if not self.is_test:\n",
        "            s2ro_map = {}\n",
        "            for triple in ins_json_data['triple_list']:\n",
        "                triple = (self.tokenizer.tokenize(triple[0]), triple[1], self.tokenizer.tokenize(triple[2]))\n",
        "                sub_head_idx = find_head_idx(tokens, triple[0])\n",
        "                obj_head_idx = find_head_idx(tokens, triple[2])\n",
        "                if sub_head_idx != -1 and obj_head_idx != -1:\n",
        "                    sub = (sub_head_idx, sub_head_idx + len(triple[0]) - 1)\n",
        "                    if sub not in s2ro_map:\n",
        "                        s2ro_map[sub] = []\n",
        "                    s2ro_map[sub].append((obj_head_idx, obj_head_idx + len(triple[2]) - 1, self.rel2id[triple[1]]))\n",
        "\n",
        "            if s2ro_map:\n",
        "                # token_ids, segment_ids = self.tokenizer.encode(first=text)\n",
        "                tokenizer_out = self.tokenizer(text)\n",
        "                token_ids = tokenizer_out['input_ids']\n",
        "                segment_ids = tokenizer_out['attention_mask']\n",
        "                masks = segment_ids\n",
        "                if len(token_ids) > text_len:\n",
        "                    token_ids = token_ids[:text_len]\n",
        "                    masks = masks[:text_len]\n",
        "                token_ids = np.array(token_ids)\n",
        "                masks = np.array(masks) + 1\n",
        "                sub_heads, sub_tails = np.zeros(text_len), np.zeros(text_len)\n",
        "                for s in s2ro_map:\n",
        "                    sub_heads[s[0]] = 1\n",
        "                    sub_tails[s[1]] = 1\n",
        "                sub_head_idx, sub_tail_idx = choice(list(s2ro_map.keys()))\n",
        "                sub_head, sub_tail = np.zeros(text_len), np.zeros(text_len)\n",
        "                sub_head[sub_head_idx] = 1\n",
        "                sub_tail[sub_tail_idx] = 1\n",
        "                obj_heads, obj_tails = np.zeros((text_len, self.config.rel_num)), np.zeros((text_len, self.config.rel_num))\n",
        "                for ro in s2ro_map.get((sub_head_idx, sub_tail_idx), []):\n",
        "                    obj_heads[ro[0]][ro[2]] = 1\n",
        "                    obj_tails[ro[1]][ro[2]] = 1\n",
        "                return token_ids, masks, text_len, sub_heads, sub_tails, sub_head, sub_tail, obj_heads, obj_tails, ins_json_data['triple_list'], tokens\n",
        "            else:\n",
        "                return None\n",
        "        else:\n",
        "            # token_ids, segment_ids = self.tokenizer.encode(first=text)\n",
        "            tokenizer_out = self.tokenizer(text)\n",
        "            token_ids = tokenizer_out['input_ids']\n",
        "            segment_ids = tokenizer_out['attention_mask']\n",
        "            masks = segment_ids\n",
        "            if len(token_ids) > text_len:\n",
        "                token_ids = token_ids[:text_len]\n",
        "                masks = masks[:text_len]\n",
        "            token_ids = np.array(token_ids)\n",
        "            masks = np.array(masks) + 1\n",
        "            sub_heads, sub_tails = np.zeros(text_len), np.zeros(text_len)\n",
        "            sub_head, sub_tail = np.zeros(text_len), np.zeros(text_len)\n",
        "            obj_heads, obj_tails = np.zeros((text_len, self.config.rel_num)), np.zeros((text_len, self.config.rel_num))\n",
        "            return token_ids, masks, text_len, sub_heads, sub_tails, sub_head, sub_tail, obj_heads, obj_tails, ins_json_data['triple_list'], tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yp80eH-4oRDy"
      },
      "outputs": [],
      "source": [
        "def cmed_collate_fn(batch):\n",
        "    batch = list(filter(lambda x: x is not None, batch))\n",
        "    batch.sort(key=lambda x: x[2], reverse=True)\n",
        "    token_ids, masks, text_len, sub_heads, sub_tails, sub_head, sub_tail, obj_heads, obj_tails, triples, tokens = zip(*batch)\n",
        "    cur_batch = len(batch)\n",
        "    max_text_len = max(text_len)\n",
        "    batch_token_ids = torch.LongTensor(cur_batch, max_text_len).zero_()\n",
        "    batch_masks = torch.LongTensor(cur_batch, max_text_len).zero_()\n",
        "    batch_sub_heads = torch.Tensor(cur_batch, max_text_len).zero_()\n",
        "    batch_sub_tails = torch.Tensor(cur_batch, max_text_len).zero_()\n",
        "    batch_sub_head = torch.Tensor(cur_batch, max_text_len).zero_()\n",
        "    batch_sub_tail = torch.Tensor(cur_batch, max_text_len).zero_()\n",
        "    batch_obj_heads = torch.Tensor(cur_batch, max_text_len, con.rel_num).zero_()\n",
        "    batch_obj_tails = torch.Tensor(cur_batch, max_text_len, con.rel_num).zero_()\n",
        "\n",
        "    for i in range(cur_batch):\n",
        "        batch_token_ids[i, :text_len[i]].copy_(torch.from_numpy(token_ids[i]))\n",
        "        batch_masks[i, :text_len[i]].copy_(torch.from_numpy(masks[i]))\n",
        "        batch_sub_heads[i, :text_len[i]].copy_(torch.from_numpy(sub_heads[i]))\n",
        "        batch_sub_tails[i, :text_len[i]].copy_(torch.from_numpy(sub_tails[i]))\n",
        "        batch_sub_head[i, :text_len[i]].copy_(torch.from_numpy(sub_head[i]))\n",
        "        batch_sub_tail[i, :text_len[i]].copy_(torch.from_numpy(sub_tail[i]))\n",
        "        batch_obj_heads[i, :text_len[i], :].copy_(torch.from_numpy(obj_heads[i]))\n",
        "        batch_obj_tails[i, :text_len[i], :].copy_(torch.from_numpy(obj_tails[i]))\n",
        "\n",
        "    return {'token_ids': batch_token_ids,\n",
        "            'mask': batch_masks,\n",
        "            'sub_heads': batch_sub_heads,\n",
        "            'sub_tails': batch_sub_tails,\n",
        "            'sub_head': batch_sub_head,\n",
        "            'sub_tail': batch_sub_tail,\n",
        "            'obj_heads': batch_obj_heads,\n",
        "            'obj_tails': batch_obj_tails,\n",
        "            'triples': triples,\n",
        "            'tokens': tokens}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "V0N7A6RIoRDy"
      },
      "outputs": [],
      "source": [
        "def get_loader(config, prefix, is_test=False, num_workers=6, collate_fn=cmed_collate_fn):\n",
        "    dataset = CMEDDataset(config, prefix, is_test, tokenizer)\n",
        "    if not is_test:\n",
        "        data_loader = DataLoader(dataset=dataset,\n",
        "                                 batch_size=config.batch_size,\n",
        "                                 shuffle=True,\n",
        "                                 pin_memory=True,\n",
        "                                 num_workers=num_workers,\n",
        "                                 collate_fn=collate_fn)\n",
        "    else:\n",
        "        data_loader = DataLoader(dataset=dataset,\n",
        "                                 batch_size=1,\n",
        "                                 shuffle=False,\n",
        "                                 pin_memory=True,\n",
        "                                 num_workers=num_workers,\n",
        "                                 collate_fn=collate_fn)\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LypQq2-OoRDy"
      },
      "outputs": [],
      "source": [
        "class DataPreFetcher(object):\n",
        "    def __init__(self, loader):\n",
        "        self.loader = iter(loader)\n",
        "        self.stream = torch.cuda.Stream()\n",
        "        self.preload()\n",
        "\n",
        "    def preload(self):\n",
        "        try:\n",
        "            self.next_data = next(self.loader)\n",
        "        except StopIteration:\n",
        "            self.next_data = None\n",
        "            return\n",
        "        with torch.cuda.stream(self.stream):\n",
        "            for k, v in self.next_data.items():\n",
        "                if isinstance(v, torch.Tensor):\n",
        "                    self.next_data[k] = self.next_data[k].cuda(non_blocking=True)\n",
        "\n",
        "    def next(self):\n",
        "        torch.cuda.current_stream().wait_stream(self.stream)\n",
        "        data = self.next_data\n",
        "        self.preload()\n",
        "        return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKNEyDDPoRDy"
      },
      "source": [
        "# Model setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CCdN5l8yoRDz"
      },
      "outputs": [],
      "source": [
        "class Casrel(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(Casrel, self).__init__()\n",
        "        self.config = config\n",
        "        self.bert_dim = 768\n",
        "        self.bert_encoder = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.sub_heads_linear = nn.Linear(self.bert_dim, 1)\n",
        "        self.sub_tails_linear = nn.Linear(self.bert_dim, 1)\n",
        "        self.obj_heads_linear = nn.Linear(self.bert_dim, self.config.rel_num)\n",
        "        self.obj_tails_linear = nn.Linear(self.bert_dim, self.config.rel_num)\n",
        "\n",
        "    def get_objs_for_specific_sub(self, sub_head_mapping, sub_tail_mapping, encoded_text):\n",
        "        # [batch_size, 1, bert_dim]\n",
        "        sub_head = torch.matmul(sub_head_mapping, encoded_text)\n",
        "        # [batch_size, 1, bert_dim]\n",
        "        sub_tail = torch.matmul(sub_tail_mapping, encoded_text)\n",
        "        # [batch_size, 1, bert_dim]\n",
        "        sub = (sub_head + sub_tail) / 2\n",
        "        # [batch_size, seq_len, bert_dim]\n",
        "        encoded_text = encoded_text + sub\n",
        "        # [batch_size, seq_len, rel_num]\n",
        "        pred_obj_heads = self.obj_heads_linear(encoded_text)\n",
        "        pred_obj_heads = torch.sigmoid(pred_obj_heads)\n",
        "        # [batch_size, seq_len, rel_num]\n",
        "        pred_obj_tails = self.obj_tails_linear(encoded_text)\n",
        "        pred_obj_tails = torch.sigmoid(pred_obj_tails)\n",
        "        return pred_obj_heads, pred_obj_tails\n",
        "\n",
        "    def get_encoded_text(self, token_ids, mask):\n",
        "        # [batch_size, seq_len, bert_dim(768)]\n",
        "        encoded_text = self.bert_encoder(token_ids, attention_mask=mask)[0]\n",
        "        return encoded_text\n",
        "\n",
        "    def get_subs(self, encoded_text):\n",
        "        # [batch_size, seq_len, 1]\n",
        "        pred_sub_heads = self.sub_heads_linear(encoded_text)\n",
        "        pred_sub_heads = torch.sigmoid(pred_sub_heads)\n",
        "        # [batch_size, seq_len, 1]\n",
        "        pred_sub_tails = self.sub_tails_linear(encoded_text)\n",
        "        pred_sub_tails = torch.sigmoid(pred_sub_tails)\n",
        "        return pred_sub_heads, pred_sub_tails\n",
        "\n",
        "    def forward(self, data):\n",
        "        # [batch_size, seq_len]\n",
        "        token_ids = data['token_ids']\n",
        "        # [batch_size, seq_len]\n",
        "        mask = data['mask']\n",
        "        # [batch_size, seq_len, bert_dim(768)]\n",
        "        encoded_text = self.get_encoded_text(token_ids, mask)\n",
        "        # [batch_size, seq_len, 1]\n",
        "        pred_sub_heads, pred_sub_tails = self.get_subs(encoded_text)\n",
        "        # [batch_size, 1, seq_len]\n",
        "        sub_head_mapping = data['sub_head'].unsqueeze(1)\n",
        "        # [batch_size, 1, seq_len]\n",
        "        sub_tail_mapping = data['sub_tail'].unsqueeze(1)\n",
        "        # [batch_size, seq_len, rel_num]\n",
        "        pred_obj_heads, pred_obj_tails = self.get_objs_for_specific_sub(sub_head_mapping, sub_tail_mapping, encoded_text)\n",
        "        return pred_sub_heads, pred_sub_tails, pred_obj_heads, pred_obj_tails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5d83e19fe14946089a0309847fd6eba2",
            "7e843e7bd41c4e3abcd6fb56b22082ca",
            "30cbef0792654a6994a233f59dff28e4",
            "8984723dbdfa4ed987852dd2c4d50a6e",
            "a4293b12b5034086a0ce071e62dd91ab",
            "5167f34c391e4fcbb695ef4bb2b70b4b",
            "77497d2fb35943b9ad5a04e8d1491d2f",
            "a337ce48732a4646a273bd350f3c51df",
            "3377048adbaa498195e670e83499f306",
            "c09dba5217ac4595a9d6b3315439d013",
            "32eaf80f955d4b7cbd03733659046f28"
          ]
        },
        "id": "votQa1Z_oRDz",
        "outputId": "d9c02cc1-74c7-401d-be3c-f36011d1f9a3",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d83e19fe14946089a0309847fd6eba2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Casrel(\n",
              "  (bert_encoder): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (sub_heads_linear): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (sub_tails_linear): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (obj_heads_linear): Linear(in_features=768, out_features=25, bias=True)\n",
              "  (obj_tails_linear): Linear(in_features=768, out_features=25, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "ori_model = Casrel(con)\n",
        "ori_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IEQOPYPSoRDz"
      },
      "outputs": [],
      "source": [
        "# define the optimizer\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, ori_model.parameters()), lr=con.learning_rate)\n",
        "\n",
        "# whether use multi GPU\n",
        "if con.multi_gpu:\n",
        "    model = nn.DataParallel(ori_model)\n",
        "else:\n",
        "    model = ori_model\n",
        "\n",
        "# define the loss function\n",
        "def loss(gold, pred, mask):\n",
        "    pred = pred.squeeze(-1)\n",
        "    los = F.binary_cross_entropy(pred, gold, reduction='none')\n",
        "    if los.shape != mask.shape:\n",
        "        mask = mask.unsqueeze(-1)\n",
        "    los = torch.sum(los * mask) / torch.sum(mask)\n",
        "    return los\n",
        "\n",
        "\n",
        "def logging(s, print_=True, log_=True):\n",
        "    if print_:\n",
        "        print(s)\n",
        "    if log_:\n",
        "        with open(os.path.join(con.log_dir, con.log_save_name), 'a+') as f_log:\n",
        "            f_log.write(s + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2rel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cE3OJY6eDeKe",
        "outputId": "cfda5cb3-bc7b-4746-8f73-550fa78bc78f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': '/business/company/founders',\n",
              " '2': '/people/person/place_of_birth',\n",
              " '3': '/people/deceased_person/place_of_death',\n",
              " '4': '/business/company_shareholder/major_shareholder_of',\n",
              " '5': '/people/ethnicity/people',\n",
              " '6': '/location/neighborhood/neighborhood_of',\n",
              " '7': '/sports/sports_team/location',\n",
              " '9': '/business/company/industry',\n",
              " '10': '/business/company/place_founded',\n",
              " '11': '/location/administrative_division/country',\n",
              " '0': 'None',\n",
              " '12': '/sports/sports_team_location/teams',\n",
              " '13': '/people/person/nationality',\n",
              " '14': '/people/person/religion',\n",
              " '15': '/business/company/advisors',\n",
              " '16': '/people/person/ethnicity',\n",
              " '17': '/people/ethnicity/geographic_distribution',\n",
              " '8': '/business/person/company',\n",
              " '19': '/business/company/major_shareholders',\n",
              " '18': '/people/person/place_lived',\n",
              " '20': '/people/person/profession',\n",
              " '21': '/location/country/capital',\n",
              " '22': '/location/location/contains',\n",
              " '23': '/location/country/administrative_divisions',\n",
              " '24': '/people/person/children'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(test_data_loader, model, output=False, h_bar=0.5, t_bar=0.5):\n",
        "\n",
        "    if output:\n",
        "        # check the result dir\n",
        "        if not os.path.exists(con.result_dir):\n",
        "            os.mkdir(con.result_dir)\n",
        "\n",
        "        path = os.path.join(con.result_dir, con.result_save_name)\n",
        "\n",
        "        fw = open(path, 'w')\n",
        "\n",
        "    orders = ['subject', 'relation', 'object']\n",
        "\n",
        "    def to_tup(triple_list):\n",
        "        ret = []\n",
        "        for triple in triple_list:\n",
        "            ret.append(tuple(triple))\n",
        "        return ret\n",
        "\n",
        "    test_data_prefetcher = DataPreFetcher(test_data_loader)\n",
        "    data = test_data_prefetcher.next()\n",
        "    id2rel = json.load(open(os.path.join(con.data_path, 'rel2id.json')))\n",
        "    correct_num, predict_num, gold_num = 0, 0, 0\n",
        "\n",
        "    while data is not None:\n",
        "        with torch.no_grad():\n",
        "            token_ids = data['token_ids']\n",
        "            tokens = data['tokens'][0]\n",
        "            mask = data['mask']\n",
        "            encoded_text = model.get_encoded_text(token_ids, mask)\n",
        "            pred_sub_heads, pred_sub_tails = model.get_subs(encoded_text)\n",
        "            print('sub_heads:',pred_sub_heads)\n",
        "            print('sub_tails:',pred_sub_tails)\n",
        "            sub_heads, sub_tails = np.where(pred_sub_heads.cpu()[0] > h_bar)[0], np.where(pred_sub_tails.cpu()[0] > t_bar)[0]\n",
        "            subjects = []\n",
        "            for sub_head in sub_heads:\n",
        "                print('for sub head in sub heads')\n",
        "                sub_tail = sub_tails[sub_tails >= sub_head]\n",
        "                if len(sub_tail) > 0:\n",
        "                    sub_tail = sub_tail[0]\n",
        "                    subject = tokens[sub_head: sub_tail]\n",
        "                    subjects.append((subject, sub_head, sub_tail))\n",
        "                    print('subject appended.')\n",
        "            if subjects:\n",
        "                print('subject if statement')\n",
        "                triple_list = []\n",
        "                # [subject_num, seq_len, bert_dim]\n",
        "                repeated_encoded_text = encoded_text.repeat(len(subjects), 1, 1)\n",
        "                # [subject_num, 1, seq_len]\n",
        "                sub_head_mapping = torch.Tensor(len(subjects), 1, encoded_text.size(1)).zero_()\n",
        "                sub_tail_mapping = torch.Tensor(len(subjects), 1, encoded_text.size(1)).zero_()\n",
        "                for subject_idx, subject in enumerate(subjects):\n",
        "                    sub_head_mapping[subject_idx][0][subject[1]] = 1\n",
        "                    sub_tail_mapping[subject_idx][0][subject[2]] = 1\n",
        "                sub_tail_mapping = sub_tail_mapping.to(repeated_encoded_text)\n",
        "                sub_head_mapping = sub_head_mapping.to(repeated_encoded_text)\n",
        "                pred_obj_heads, pred_obj_tails = model.get_objs_for_specific_sub(sub_head_mapping, sub_tail_mapping, repeated_encoded_text)\n",
        "                for subject_idx, subject in enumerate(subjects):\n",
        "                    sub = subject[0]\n",
        "                    sub = ''.join([i.lstrip(\"##\") for i in sub])\n",
        "                    sub = ' '.join(sub.split('[unused1]'))\n",
        "                    obj_heads, obj_tails = np.where(pred_obj_heads.cpu()[subject_idx] > h_bar), np.where(pred_obj_tails.cpu()[subject_idx] > t_bar)\n",
        "                    for obj_head, rel_head in zip(*obj_heads):\n",
        "                        for obj_tail, rel_tail in zip(*obj_tails):\n",
        "                            if obj_head <= obj_tail and rel_head == rel_tail:\n",
        "                                rel = id2rel[str(int(rel_head))]\n",
        "                                obj = tokens[obj_head: obj_tail]\n",
        "                                obj = ''.join([i.lstrip(\"##\") for i in obj])\n",
        "                                obj = ' '.join(obj.split('[unused1]'))\n",
        "                                print('pred subject:', sub)\n",
        "                                print('pred relation:',rel)\n",
        "                                print('pred object:', obj)\n",
        "                                triple_list.append((sub, rel, obj))\n",
        "                                break\n",
        "                triple_set = set()\n",
        "                for s, r, o in triple_list:\n",
        "                    triple_set.add((s, r, o))\n",
        "                pred_list = list(triple_set)\n",
        "            else:\n",
        "                print('subject else statement')\n",
        "                pred_list = []\n",
        "            pred_triples = set(pred_list)\n",
        "            gold_triples = set(to_tup(data['triples'][0]))\n",
        "\n",
        "            correct_num += len(pred_triples & gold_triples)\n",
        "            predict_num += len(pred_triples)\n",
        "            gold_num += len(gold_triples)\n",
        "\n",
        "            if output:\n",
        "                result = json.dumps({\n",
        "                    # 'text': ' '.join(tokens),\n",
        "                    'triple_list_gold': [\n",
        "                        dict(zip(orders, triple)) for triple in gold_triples\n",
        "                    ],\n",
        "                    'triple_list_pred': [\n",
        "                        dict(zip(orders, triple)) for triple in pred_triples\n",
        "                    ],\n",
        "                    'new': [\n",
        "                        dict(zip(orders, triple)) for triple in pred_triples - gold_triples\n",
        "                    ],\n",
        "                    'lack': [\n",
        "                        dict(zip(orders, triple)) for triple in gold_triples - pred_triples\n",
        "                    ]\n",
        "                }, ensure_ascii=False)\n",
        "                fw.write(result + '\\n')\n",
        "\n",
        "            data = test_data_prefetcher.next()\n",
        "\n",
        "    print(\"correct_num: {:3d}, predict_num: {:3d}, gold_num: {:3d}\".format(correct_num, predict_num, gold_num))\n",
        "\n",
        "    precision = correct_num / (predict_num + 1e-10)\n",
        "    recall = correct_num / (gold_num + 1e-10)\n",
        "    f1_score = 2 * precision * recall / (precision + recall + 1e-10)\n",
        "    return precision, recall, f1_score"
      ],
      "metadata": {
        "id": "vRmpWkicZj1i"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATYRl27EoRD0"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "FOAdhIA7oRD0"
      },
      "outputs": [],
      "source": [
        "# check the checkpoint dir\n",
        "if not os.path.exists(con.checkpoint_dir):\n",
        "    os.mkdir(con.checkpoint_dir)\n",
        "\n",
        "# check the log dir\n",
        "if not os.path.exists(con.log_dir):\n",
        "    os.mkdir(con.log_dir)\n",
        "\n",
        "# get the data loader\n",
        "#train_data_loader = data_loader.get_loader(con, prefix=con.train_prefix)\n",
        "train_data_loader = get_loader(con, prefix=con.train_prefix)\n",
        "dev_data_loader = get_loader(con, prefix=con.dev_prefix, is_test=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "global_step = 0\n",
        "loss_sum = 0\n",
        "\n",
        "best_f1_score = 0\n",
        "best_precision = 0\n",
        "best_recall = 0\n",
        "\n",
        "best_epoch = 0\n",
        "init_time = time.time()\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(con.max_epoch):\n",
        "    train_data_prefetcher = DataPreFetcher(train_data_loader)\n",
        "    data = train_data_prefetcher.next()\n",
        "\n",
        "    while data is not None:\n",
        "        pred_sub_heads, pred_sub_tails, pred_obj_heads, pred_obj_tails = model(data)\n",
        "\n",
        "        sub_heads_loss = loss(data['sub_heads'], pred_sub_heads, data['mask'])\n",
        "        sub_tails_loss = loss(data['sub_tails'], pred_sub_tails, data['mask'])\n",
        "        obj_heads_loss = loss(data['obj_heads'], pred_obj_heads, data['mask'])\n",
        "        obj_tails_loss = loss(data['obj_tails'], pred_obj_tails, data['mask'])\n",
        "        total_loss = (sub_heads_loss + sub_tails_loss) + (obj_heads_loss + obj_tails_loss)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        global_step += 1\n",
        "        loss_sum += total_loss.item()\n",
        "\n",
        "        if global_step % con.period == 0:\n",
        "            cur_loss = loss_sum / con.period\n",
        "            elapsed = time.time() - start_time\n",
        "            #logging(\"epoch: {:3d}, step: {:4d}, speed: {:5.2f}ms/b, train loss: {:5.3f}\".\n",
        "                          format(epoch, global_step, elapsed * 1000 / con.period, cur_loss))\n",
        "            loss_sum = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "        data = train_data_prefetcher.next()\n",
        "        \n",
        "\n",
        "\n",
        "    if (epoch + 1) % con.test_epoch == 0:\n",
        "        eval_start_time = time.time()\n",
        "        model.eval()\n",
        "        # call the test function\n",
        "        precision, recall, f1_score = test(dev_data_loader, model)\n",
        "        model.train()\n",
        "        #logging('epoch {:3d}, eval time: {:5.2f}s, f1: {:4.2f}, precision: {:4.2f}, recall: {:4.2f}'.\n",
        "                      format(epoch, time.time() - eval_start_time, f1_score, precision, recall))\n",
        "\n",
        "        if f1_score > best_f1_score:\n",
        "            best_f1_score = f1_score\n",
        "            best_epoch = epoch\n",
        "            best_precision = precision\n",
        "            best_recall = recall\n",
        "            #logging(\"saving the model, epoch: {:3d}, best f1: {:4.2f}, precision: {:4.2f}, recall: {:4.2f}\".\n",
        "                          format(best_epoch, best_f1_score, precision, recall))\n",
        "            # save the best model\n",
        "            path = os.path.join(con.checkpoint_dir, con.model_save_name)\n",
        "            if not con.debug:\n",
        "                torch.save(ori_model.state_dict(), path)\n",
        "\n",
        "            # manually release the unused cache\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(\"finish training\")\n",
        "print(\"best epoch: {:3d}, best f1: {:4.2f}, precision: {:4.2f}, recall: {:4.2}, total time: {:5.2f}s\".\n",
        "              format(best_epoch, best_f1_score, best_precision, best_recall, time.time() - init_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsiaiB576-XG",
        "outputId": "442ce901-bc5f-41c3-edd1-113dc20c61e0"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish training\n",
            "best epoch: 217, best f1: 77.73, precision: 90.20, recall: 9.1e+01, total time: 208936.00s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "ceklDRuezEgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = os.path.join(con.checkpoint_dir, con.model_save_name)\n",
        "model = model.load_state_dict(torch.load(path))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "test_data_loader = get_loader(con, prefix=con.test_prefix, is_test=True)\n",
        "precision, recall, f1_score = test(test_data_loader, model, True)\n",
        "print(\"f1: {:4.2f}, precision: {:4.2f}, recall: {:4.2f}\".format(f1_score, precision, recall))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEoAgBDM7bVz",
        "outputId": "a9115322-4be3-4ec4-a547-d8097eb450ca"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1: 89.62, precision: 89.67, recall: 89.49\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "85c629e1261c45258099cac20ae93a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eeaede3c17854fc884ec86fb6671f9a9",
              "IPY_MODEL_ecbd5e139a324336a2f66fa81daff8a0",
              "IPY_MODEL_0b17cc9fbe134ab8bfda63f16c857354"
            ],
            "layout": "IPY_MODEL_b2e7ed35c4f74bd69673467fad7dacac"
          }
        },
        "eeaede3c17854fc884ec86fb6671f9a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee1008c9342742ca93f596ac02354cca",
            "placeholder": "​",
            "style": "IPY_MODEL_04a020d344764dbaa9b65bc2f8663c1f",
            "value": "Downloading: 100%"
          }
        },
        "ecbd5e139a324336a2f66fa81daff8a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6fc2a90096048b8b22a49da90f37411",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0331243d251e4cc092365e0342eb9a75",
            "value": 231508
          }
        },
        "0b17cc9fbe134ab8bfda63f16c857354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7243c52e40c1485885fb16409e56e8a7",
            "placeholder": "​",
            "style": "IPY_MODEL_7c0e8c317bf7478d8792e208062173e3",
            "value": " 232k/232k [00:00&lt;00:00, 1.51MB/s]"
          }
        },
        "b2e7ed35c4f74bd69673467fad7dacac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee1008c9342742ca93f596ac02354cca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04a020d344764dbaa9b65bc2f8663c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6fc2a90096048b8b22a49da90f37411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0331243d251e4cc092365e0342eb9a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7243c52e40c1485885fb16409e56e8a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c0e8c317bf7478d8792e208062173e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cbfa643d0f94b8e9e600ef2f9790c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1683dc0fdaf64063ac17ace7964a218d",
              "IPY_MODEL_14ac2ddf2fff4200b71770b3ce315a1d",
              "IPY_MODEL_188cc792d6584f9a8fb41fffc6232d07"
            ],
            "layout": "IPY_MODEL_b0d2b0a2a39944868e005f025c29325c"
          }
        },
        "1683dc0fdaf64063ac17ace7964a218d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6b25463dc2c4e91beabca3292856f05",
            "placeholder": "​",
            "style": "IPY_MODEL_b24c02447fa24936b3eef12cc6519f4d",
            "value": "Downloading: 100%"
          }
        },
        "14ac2ddf2fff4200b71770b3ce315a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_248510a1141347dc8c6a985c4a0fd7c8",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12dffa4cd7b642c0afbf4a9a913cdea2",
            "value": 28
          }
        },
        "188cc792d6584f9a8fb41fffc6232d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c76ca8cd1c34258bbbb7be473b8fd4a",
            "placeholder": "​",
            "style": "IPY_MODEL_db11a8a4bc1b43a8a06557d34350ba84",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.04kB/s]"
          }
        },
        "b0d2b0a2a39944868e005f025c29325c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6b25463dc2c4e91beabca3292856f05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b24c02447fa24936b3eef12cc6519f4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "248510a1141347dc8c6a985c4a0fd7c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12dffa4cd7b642c0afbf4a9a913cdea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c76ca8cd1c34258bbbb7be473b8fd4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db11a8a4bc1b43a8a06557d34350ba84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91b1ac3f20164d6995c2a54f406818b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7023bd59b09b49069d6464781a22567e",
              "IPY_MODEL_fb641842ab5d43169ae597d7e51f41e6",
              "IPY_MODEL_81af793eb449404487cd22d5db65de09"
            ],
            "layout": "IPY_MODEL_b9731845b1e84dc7a1101634515d834b"
          }
        },
        "7023bd59b09b49069d6464781a22567e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c572966776bf4361a3761674b2679fcf",
            "placeholder": "​",
            "style": "IPY_MODEL_0c3928456a8043658497699e1f65e91c",
            "value": "Downloading: 100%"
          }
        },
        "fb641842ab5d43169ae597d7e51f41e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_348261ac505e41bfae5b44fc49839418",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_497a6437c9784d3592ff15bb8ecb05a7",
            "value": 570
          }
        },
        "81af793eb449404487cd22d5db65de09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d80d413c845f4ba1b7186c4878abba65",
            "placeholder": "​",
            "style": "IPY_MODEL_6573b2b470304d158d7e0ba1e3ffc1b7",
            "value": " 570/570 [00:00&lt;00:00, 19.9kB/s]"
          }
        },
        "b9731845b1e84dc7a1101634515d834b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c572966776bf4361a3761674b2679fcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c3928456a8043658497699e1f65e91c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "348261ac505e41bfae5b44fc49839418": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "497a6437c9784d3592ff15bb8ecb05a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d80d413c845f4ba1b7186c4878abba65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6573b2b470304d158d7e0ba1e3ffc1b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d83e19fe14946089a0309847fd6eba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e843e7bd41c4e3abcd6fb56b22082ca",
              "IPY_MODEL_30cbef0792654a6994a233f59dff28e4",
              "IPY_MODEL_8984723dbdfa4ed987852dd2c4d50a6e"
            ],
            "layout": "IPY_MODEL_a4293b12b5034086a0ce071e62dd91ab"
          }
        },
        "7e843e7bd41c4e3abcd6fb56b22082ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5167f34c391e4fcbb695ef4bb2b70b4b",
            "placeholder": "​",
            "style": "IPY_MODEL_77497d2fb35943b9ad5a04e8d1491d2f",
            "value": "Downloading: 100%"
          }
        },
        "30cbef0792654a6994a233f59dff28e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a337ce48732a4646a273bd350f3c51df",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3377048adbaa498195e670e83499f306",
            "value": 440473133
          }
        },
        "8984723dbdfa4ed987852dd2c4d50a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c09dba5217ac4595a9d6b3315439d013",
            "placeholder": "​",
            "style": "IPY_MODEL_32eaf80f955d4b7cbd03733659046f28",
            "value": " 440M/440M [00:07&lt;00:00, 64.5MB/s]"
          }
        },
        "a4293b12b5034086a0ce071e62dd91ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5167f34c391e4fcbb695ef4bb2b70b4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77497d2fb35943b9ad5a04e8d1491d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a337ce48732a4646a273bd350f3c51df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3377048adbaa498195e670e83499f306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c09dba5217ac4595a9d6b3315439d013": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32eaf80f955d4b7cbd03733659046f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}